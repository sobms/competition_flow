#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç prepare_dataset –±–µ–∑ Hydra.
"""

import sys
import logging
import time
from pathlib import Path
from omegaconf import OmegaConf

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(str(Path(__file__).parent))

from ml.models import SASRecAdapter

# –í–∫–ª—é—á–∞–µ–º INFO-–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ prepare_dataset
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s: %(message)s"
)
logging.getLogger("ml.models.recbole_base").setLevel(logging.INFO)


def main():
    """–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—É—Å–∫ prepare_dataset —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π."""
    
    # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    cfg_dict = {
        "seed": 42,
        "artifacts_dir": "artifacts",
        "model": {
            "USER_ID_FIELD": "user_id",
            "ITEM_ID_FIELD": "item_id", 
            "LABEL_FIELD": "target",
            "TIME_FIELD": "date",
            "inter_features_dir": "data/processed_features/inter_features",
            "items_dir": "data/processed_features/items_features", 
            "users_dir": "data/processed_features/users_features",
            "base_cols": [
                {"name": "user_id", "type": "token"},
                {"name": "item_id", "type": "token"},
                {"name": "target", "type": "float"},
                {"name": "date", "type": "float"}
            ],
            "inter_feature_cols": [
                {"name": "cnt_view_description_sum_30d_past", "type": "int"},
                {"name": "cnt_page_view_sum_30d_past", "type": "int"},
                {"name": "cnt_favorite_sum_30d_past", "type": "int"},
                {"name": "cnt_unfavorite_sum_30d_past", "type": "int"},
                {"name": "cnt_to_cart_sum_30d_past", "type": "int"},
                {"name": "cnt_remove_sum_30d_past", "type": "int"},
                {"name": "cnt_review_view_sum_30d_past", "type": "int"}
            ],
            "item_feature_cols": [
                {"name": "fclip_embed", "type": "float_seq"},
                # {"name": "catalogid", "type": "token"},
                # {"name": "variant_id", "type": "token"},
                # {"name": "model_id", "type": "token"}
            ],
            "auxiliary_feature_cols": [
                {"name": "item_id_list", "type": "float_seq"},
                {"name": "item_length", "type": "float"}
            ]
        }
    }
    
    cfg = OmegaConf.create(cfg_dict)
    
    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RecBoleBaseAdapter...")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–¥–∞–ø—Ç–µ—Ä–∞ –¥–ª—è SASRec (RecBole –∫–æ–Ω—Ñ–∏–≥ –∫–ª—é—á–∏ –ø–µ—Ä–µ–¥–∞–µ–º –ø–ª–æ—Å–∫–æ)
    adapter_params = {
        "model": "SASRec",
        "batch_size": 512,           # –¥–ª—è –Ω–∞—à–µ–≥–æ DataLoader
        "use_gpu": False,            # —Ç–µ—Å—Ç –±–µ–∑ GPU
        "infer_batch_size": 512,
        # SASRec/RecBole –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        "hidden_size": 128,
        "num_layers": 2,
        "num_heads": 2,
        "dropout_prob": 0.2,
        "attn_dropout_prob": 0.2,
        "hidden_dropout_prob": 0.2,
        "max_seq_length": 50,        # –¥–ª–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏, —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞—à–∏–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º
        "learning_rate": 0.001,
        "epochs": 1,                 # –±—ã—Å—Ç—Ä–µ–µ –¥–ª—è —Ç–µ—Å—Ç–∞
        "train_batch_size": 1024,
        "eval_batch_size": 1024,
        # –æ—Ç–∫–ª—é—á–∞–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è CE –≤ SASRec
        "train_neg_sample_args": None,
        "eval_neg_sample_args": None,
    }
    
    adapter = SASRecAdapter(**adapter_params)
    
    print("–ó–∞–ø—É—Å–∫ prepare_dataset...")
    try:
        train_data, valid_data = adapter.prepare_dataset(cfg)
        
        print("\n‚úÖ prepare_dataset –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"Train data keys: {list(train_data.keys())}")
        print(f"Valid data keys: {list(valid_data.keys())}")
        
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(adapter.user_id_to_idx)}")
        print(f"- –¢–æ–≤–∞—Ä–æ–≤: {len(adapter.item_id_to_idx)}")
        
        if valid_data.get("users"):
            print(f"- –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(valid_data['users'])}")
        
        if valid_data.get("ground_truth"):
            print(f"- Ground truth –ø–∞—Ä: {len(valid_data['ground_truth'])}")
            
        # –ü—Ä–æ–≤–µ—Ä–∏–º –æ–¥–∏–Ω –±–∞—Ç—á
        train_loader = train_data.get("train_loader")
        if train_loader is not None:
            print(f"\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ train_loader:")
            print(f"- Batch size: {train_loader.batch_size}")
            
            # –ò–∑–º–µ—Ä–∏–º –≤—Ä–µ–º—è –ø–µ—Ä–≤—ã—Ö —Ç—Ä–µ—Ö –±–∞—Ç—á–µ–π
            print("[TEST] Timing first 3 batches...")
            it = iter(train_loader)
            for i in range(3):
                try:
                    t0 = time.time()
                    b = next(it)
                    dt = time.time() - t0
                    # –û–ø—Ä–µ–¥–µ–ª–∏–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
                    bs = 0
                    try:
                        if hasattr(b, 'interaction'):
                            keys_b = list(b.interaction.keys())
                            for k in keys_b:
                                v = b.interaction[k]
                                if hasattr(v, 'shape') and len(getattr(v, 'shape', [])) > 0:
                                    bs = int(v.shape[0])
                                    break
                                elif isinstance(v, (list, tuple)) and len(v) > 0:
                                    bs = len(v)
                                    break
                        elif isinstance(b, dict):
                            for k, v in b.items():
                                if hasattr(v, 'shape') and len(getattr(v, 'shape', [])) > 0:
                                    bs = int(v.shape[0])
                                    break
                                elif isinstance(v, (list, tuple)) and len(v) > 0:
                                    bs = len(v)
                                    break
                    except Exception:
                        bs = 0
                    print(f"- Batch {i+1}: {dt:.3f}s (size={bs})")
                except StopIteration:
                    print(f"- Batch {i+1}: no more data")
                    break
                except Exception as e:
                    print(f"- Batch {i+1}: error {e}")
                    break
            
            try:
                batch = next(iter(train_loader))
                # RecBole –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Interaction –æ–±—ä–µ–∫—Ç, –∞ –Ω–µ –æ–±—ã—á–Ω—ã–π dict
                if hasattr(batch, 'interaction'):
                    keys = list(batch.interaction.keys())
                    print(f"- –ü–æ–ª—è –≤ –±–∞—Ç—á–µ: {keys}")
                    for key in keys:
                        value = batch.interaction[key]
                        if hasattr(value, 'shape'):
                            print(f"  {key}: {value.shape} ({value.dtype})")
                        else:
                            print(f"  {key}: {type(value)} (len={len(value) if hasattr(value, '__len__') else 'N/A'})")
                else:
                    print(f"- –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø –±–∞—Ç—á–∞: {type(batch)}")
            except Exception as e:
                print(f"- ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –±–∞—Ç—á–∞: {e}")

            # –ò–∑–º–µ—Ä–∏–º —Å–∫–æ—Ä–æ—Å—Ç—å –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ train_loader (–æ–≥—Ä–∞–Ω–∏—á–∏–º –¥–æ N –±–∞—Ç—á–µ–π)
            def measure_loader_speed(loader, max_batches: int = 200):
                start = time.time()
                total_rows = 0
                num_batches = 0
                for i, b in enumerate(loader):
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–æ –ø–µ—Ä–≤–æ–º—É —Ç–µ–Ω–∑–æ—Ä–Ω–æ–º—É –ø–æ–ª—é
                    bs = 0
                    try:
                        # RecBole –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Interaction –æ–±—ä–µ–∫—Ç
                        if hasattr(b, 'interaction'):
                            keys = list(b.interaction.keys())
                            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è (user_id, item_id)
                            priority_keys = ['user_id', 'item_id', 'target', 'date']
                            check_keys = [k for k in priority_keys if k in keys] + [k for k in keys if k not in priority_keys]
                            
                            for k in check_keys:
                                v = b.interaction[k]
                                # –î–ª—è torch.Tensor
                                if hasattr(v, 'shape') and len(getattr(v, 'shape', [])) > 0:
                                    bs = int(v.shape[0])
                                    break
                                # –î–ª—è —Å–ø–∏—Å–∫–æ–≤/–∫–æ—Ä—Ç–µ–∂–µ–π
                                elif isinstance(v, (list, tuple)) and len(v) > 0:
                                    bs = len(v)
                                    break
                                # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å __len__
                                elif hasattr(v, '__len__') and not isinstance(v, str):
                                    try:
                                        bs = len(v)
                                        if bs > 0:
                                            break
                                    except:
                                        pass
                        else:
                            # Fallback –¥–ª—è –æ–±—ã—á–Ω—ã—Ö dict
                            keys = list(b.keys())
                            for k in keys:
                                v = b[k]
                                if hasattr(v, 'shape') and len(getattr(v, 'shape', [])) > 0:
                                    bs = int(v.shape[0])
                                    break
                    except Exception:
                        bs = 0
                    total_rows += bs
                    num_batches += 1
                    if max_batches is not None and (i + 1) >= max_batches:
                        break
                elapsed = time.time() - start
                ips = (total_rows / elapsed) if elapsed > 0 else 0.0
                bps = (num_batches / elapsed) if elapsed > 0 else 0.0
                return {
                    "batches": num_batches,
                    "rows": total_rows,
                    "seconds": elapsed,
                    "rows_per_sec": ips,
                    "batches_per_sec": bps,
                }

            stats = measure_loader_speed(train_loader, max_batches=200)
            print("\nüöÄ –°–∫–æ—Ä–æ—Å—Ç—å –∏—Ç–µ—Ä–∞—Ü–∏–∏ train_loader (–ø–µ—Ä–≤—ã–µ 200 –±–∞—Ç—á–µ–π):")
            print(f"- Batches: {stats['batches']}")
            print(f"- Rows: {stats['rows']}")
            print(f"- Time: {stats['seconds']:.3f}s")
            print(f"- Rows/sec: {stats['rows_per_sec']:.1f}")
            print(f"- Batches/sec: {stats['batches_per_sec']:.1f}")

        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –∑–∞–º–µ—Ä–∏–º valid_loader, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        valid_loader = valid_data.get("valid_loader")
        if valid_loader is not None:
            stats_v = measure_loader_speed(valid_loader, max_batches=200)
            print("\nüöÄ –°–∫–æ—Ä–æ—Å—Ç—å –∏—Ç–µ—Ä–∞—Ü–∏–∏ valid_loader (–ø–µ—Ä–≤—ã–µ 200 –±–∞—Ç—á–µ–π):")
            print(f"- Batches: {stats_v['batches']}")
            print(f"- Rows: {stats_v['rows']}")
            print(f"- Time: {stats_v['seconds']:.3f}s")
            print(f"- Rows/sec: {stats_v['rows_per_sec']:.1f}")
            print(f"- Batches/sec: {stats_v['batches_per_sec']:.1f}")
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ prepare_dataset: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

